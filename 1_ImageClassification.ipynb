{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"1_ImageClassification.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPc4vmhH6nFNobrlYxtcUNX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"d6557963bb894edbadff3937eacd39f9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_9d335848b6504f1bae6d84f132e33258","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_74619af1e1ec4514b0bcd25e69b72865","IPY_MODEL_fb8d6de07ae94ebab85b624aa24d4700"]}},"9d335848b6504f1bae6d84f132e33258":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"74619af1e1ec4514b0bcd25e69b72865":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_5a1c9d30ea384cc69abc17aa6ec35922","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":553433881,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":553433881,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e819faf189fa4ddfa98b7b7fadb5d420"}},"fb8d6de07ae94ebab85b624aa24d4700":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ba663d5e584445be9275be6bb52fb552","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 528M/528M [01:06&lt;00:00, 8.26MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_06787fc8e7b948a5aff4f3d78bd956d6"}},"5a1c9d30ea384cc69abc17aa6ec35922":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e819faf189fa4ddfa98b7b7fadb5d420":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ba663d5e584445be9275be6bb52fb552":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"06787fc8e7b948a5aff4f3d78bd956d6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"ZOntMjde9hoD","colab_type":"text"},"source":["# ファイル準備"]},{"cell_type":"code","metadata":{"id":"sQ4hk7o063bY","colab_type":"code","colab":{}},"source":["import os\n","import urllib.request\n","import zipfile"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A_61Baow8pcn","colab_type":"code","colab":{}},"source":["data_dir = './data'\n","if not os.path.exists(data_dir):\n","    os.mkdir(data_dir)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A8hOAAHZ84UI","colab_type":"code","colab":{}},"source":["url = \"https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json\"\n","save_path = os.path.join(data_dir, \"imagenet_class_index.json\")\n","\n","if not os.path.exists(save_path):\n","    urllib.request.urlretrieve(url, save_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zKCEJgR1-ECC","colab_type":"code","colab":{}},"source":["url = \"https://download.pytorch.org/tutorial/hymenoptera_data.zip\"\n","save_path = os.path.join(data_dir, 'hymenoptera_data.zip')\n","\n","if not os.path.exists(save_path):\n","    urllib.request.urlretrieve(url, save_path)\n","\n","    zip_file = zipfile.ZipFile(save_path)\n","    zip_file.extractall(data_dir)\n","    zip_file.close()\n","\n","    os.remove(save_path)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"95ZWKk5x_WDe","colab_type":"text"},"source":["# version確認"]},{"cell_type":"code","metadata":{"id":"FPnWQl6E--WA","colab_type":"code","colab":{}},"source":["import numpy as np\n","import json\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","import torch\n","import torchvision\n","from torchvision import models, transforms"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BVyDOtrE_xJx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1599614467733,"user_tz":-540,"elapsed":8682,"user":{"displayName":"Daisuke Kubo","photoUrl":"","userId":"01125598221336647455"}},"outputId":"6e48c170-c7c6-40a9-f2f9-208a5af58514"},"source":["torchvision.__version__"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'0.7.0+cu101'"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"ju3KYl3xB1c8","colab_type":"text"},"source":["# Classification of image, using VGG-16"]},{"cell_type":"markdown","metadata":{"id":"kFeGJOevAEtz","colab_type":"text"},"source":["## loading pre-trained model"]},{"cell_type":"code","metadata":{"id":"q_OKpZA-_1UB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":871,"referenced_widgets":["d6557963bb894edbadff3937eacd39f9","9d335848b6504f1bae6d84f132e33258","74619af1e1ec4514b0bcd25e69b72865","fb8d6de07ae94ebab85b624aa24d4700","5a1c9d30ea384cc69abc17aa6ec35922","e819faf189fa4ddfa98b7b7fadb5d420","ba663d5e584445be9275be6bb52fb552","06787fc8e7b948a5aff4f3d78bd956d6"]},"executionInfo":{"status":"ok","timestamp":1599614493430,"user_tz":-540,"elapsed":34356,"user":{"displayName":"Daisuke Kubo","photoUrl":"","userId":"01125598221336647455"}},"outputId":"8b0bf143-f0e2-4bd6-fdff-23735b14ae53"},"source":["use_pretrained = True\n","model = models.vgg16(pretrained=use_pretrained)\n","model.eval()\n","\n","print(model)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d6557963bb894edbadff3937eacd39f9","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=553433881.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","VGG(\n","  (features): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU(inplace=True)\n","    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): ReLU(inplace=True)\n","    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (6): ReLU(inplace=True)\n","    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (8): ReLU(inplace=True)\n","    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): ReLU(inplace=True)\n","    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (13): ReLU(inplace=True)\n","    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (15): ReLU(inplace=True)\n","    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (18): ReLU(inplace=True)\n","    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (20): ReLU(inplace=True)\n","    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (22): ReLU(inplace=True)\n","    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (25): ReLU(inplace=True)\n","    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (27): ReLU(inplace=True)\n","    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (29): ReLU(inplace=True)\n","    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n","  (classifier): Sequential(\n","    (0): Linear(in_features=25088, out_features=4096, bias=True)\n","    (1): ReLU(inplace=True)\n","    (2): Dropout(p=0.5, inplace=False)\n","    (3): Linear(in_features=4096, out_features=4096, bias=True)\n","    (4): ReLU(inplace=True)\n","    (5): Dropout(p=0.5, inplace=False)\n","    (6): Linear(in_features=4096, out_features=1000, bias=True)\n","  )\n",")\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"t0Ax5PilCEK3","colab_type":"text"},"source":["## pre-processing"]},{"cell_type":"code","metadata":{"id":"wW_xt2JFAeIg","colab_type":"code","colab":{}},"source":["\"\"\"pre-processing of input image\"\"\"\n","\n","class BaseTransform():\n","    \"\"\"Resize image and Normalize color\n","\n","    Attributes\n","        resize(int): the scale after resizing image\n","\n","        mean(R, G, B): average of color channels\n","\n","        std(R, G, B): standard deviation of color channels\n","    \"\"\"\n","\n","    def __init__(self, resize, mean, std):\n","        self.base_transform = transforms.Compose([\n","            transforms.Resize(resize), # 短い辺の長さがresizeの大きさになる\n","            transforms.CenterCrop(resize), # 画像中央をresize * resizeで切り取り\n","            transforms.ToTensor(),\n","            transforms.Normalize(mean, std)\n","        ])\n","\n","    def __call__(self, img):\n","        return self.base_transform(img)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JFeUkPE8iC-T","colab_type":"code","colab":{}},"source":["class BaseTransform():\n","    \"\"\"\n","    画像のサイズをリサイズし、色を標準化する。\n","\n","    Attributes\n","    ----------\n","    resize : int\n","        リサイズ先の画像の大きさ。\n","    mean : (R, G, B)\n","        各色チャネルの平均値。\n","    std : (R, G, B)\n","        各色チャネルの標準偏差。\n","    \"\"\"\n","\n","    def __init__(self, resize, mean, std):\n","        self.base_transform = transforms.Compose([\n","            transforms.Resize(resize),  # 短い辺の長さがresizeの大きさになる\n","            transforms.CenterCrop(resize),  # 画像中央をresize × resizeで切り取り\n","            transforms.ToTensor(),  # Torchテンソルに変換\n","            transforms.Normalize(mean, std)  # 色情報の標準化\n","        ])\n","\n","    def __call__(self, img):\n","        return self.base_transform(img)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rceORVOhEiZI","colab_type":"code","colab":{}},"source":["\"\"\"check pre-processing\"\"\"\n","\n","# load image\n","img_file_path = './data/goldenretriever-3724972_640.jpg'\n","img = Image.open(img_file_path).convert('RGB')\n","\n","# print original image\n","plt.imshow(img)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DfdgsUDyiHl2","colab_type":"code","colab":{}},"source":["# pre-processing image, and print pre-processed image\n","resize = 224\n","mean = (0.485, 0.456, 0.406)\n","std = (0.229, 0.224, 0.225)\n","transform = BaseTransform(resize, mean, std)\n","img_transformed = transform(img)  # torch.Size([3, 224, 224])\n","\n","# change (color, height, width) to (height, width, color)\n","img_transformed = img_transformed.permute(1, 2, 0)\n","img_transformed = np.clip(img_transformed, 0, 1)\n","plt.imshow(img_transformed)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4rOL4DnOkSNn","colab_type":"text"},"source":["## post-processing"]},{"cell_type":"code","metadata":{"id":"qT-0kfdKFDGM","colab_type":"code","colab":{}},"source":["ILSVRC_class_index = json.load(open('./data/imagenet_class_index.json', 'r'))\n","ILSVRC_class_index"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YyD3HhpnkvHN","colab_type":"code","colab":{}},"source":["# post-processing class predicting label from output result\n","\n","class ILSVRCPredictor():\n","    \"\"\" Predict label from model output\n","    \n","    attribute:\n","    class index(dict): class index -> label\n","\n","    \"\"\"\n","\n","    def __init__(self, class_index):\n","        self.class_index = class_index\n","    \n","    def predict_max(self, out):\n","        \"\"\" Get label of ILSVRC to maximize prob.\n","\n","        arg:\n","            out: torch.size([1, 1000])\n","        \n","        return:\n","            predicted_label_name(str): label name of most highest predicted prob\n","        \"\"\"\n","\n","        maxid = np.argmax(out.detach().numpy()) # detach out from network, then change type of numpy\n","        predicted_label_name = self.class_index[str(maxid)][1]\n","\n","        return predicted_label_name"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zteRAlQqoJna","colab_type":"text"},"source":["## predict image using trained VGG-16"]},{"cell_type":"code","metadata":{"id":"XOOF0DbxoT-i","colab_type":"code","colab":{}},"source":["# generate valuable(type(dict))\n","ILSVRC_class_index = json.load(open('./data/imagenet_class_index.json', 'r'))\n","\n","# generate instance\n","predictor = ILSVRCPredictor(ILSVRC_class_index)\n","\n","# load input image\n","img_file_path = './data/goldenretriever-3724972_640.jpg'\n","img = Image.open(img_file_path)\n","\n","# pre-processing\n","transform = BaseTransform(resize, mean, std)\n","img_transformed = transform(img) # torch.size([3, 224, 224])\n","inputs = img_transformed.unsqueeze_(0) # add dimension of batch_size # torch.size([1, 3, 224, 224])\n","\n","# input to model, then transform model_output to label\n","out = model(inputs) # torch.size([1, 1000])\n","result = predictor.predict_max(out)\n","\n","print(f'predicted label: {result}')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fJae0aMhqXwf","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L024GXWGqldN","colab_type":"text"},"source":["# Transfer learning"]},{"cell_type":"code","metadata":{"id":"3IHVl3_QGOqN","colab_type":"code","colab":{}},"source":["import glob\n","import os\n","import random\n","import numpy as np\n","import json\n","from PIL import Image\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","plt.style.use('ggplot')\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.utils.data as data\n","import torchvision\n","from torchvision import models, transforms\n","from torch.utils.data import DataLoader"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VH7qLd2zHLT4","colab_type":"code","colab":{}},"source":["# setting seed of random number\n","torch.manual_seed(1234)\n","np.random.seed(1234)\n","random.seed(1234)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aT93erOSGGxE","colab_type":"text"},"source":["## Create Dataset"]},{"cell_type":"markdown","metadata":{"id":"gR_JwL_NMiHM","colab_type":"text"},"source":["### pre-processing"]},{"cell_type":"code","metadata":{"id":"FUQtfI10GVXC","colab_type":"code","colab":{}},"source":["# pre-process input image\n","class ImageTransform():\n","    \"\"\"Pre-process input image(Resize image, and Normalize color)\n","\n","    Attribute\n","    ---------\n","    resize(int)\n","    mean(R,G,B)\n","    std(R,G,B)\n","    \"\"\"\n","    def __init__(self, resize, mean, std):\n","        self.data_transform = {\n","            'train': transforms.Compose([\n","                transforms.RandomResizedCrop(resize, scale=(0.5, 1.0)),\n","                transforms.RandomHorizontalFlip(),\n","                transforms.ToTensor(),\n","                transforms.Normalize(mean, std)\n","            ]),\n","            'val': transforms.Compose([\n","                transforms.Resize(resize),\n","                transforms.CenterCrop(resize),\n","                transforms.ToTensor(),\n","                transforms.Normalize(mean, std)\n","            ])\n","        }\n","\n","    def __call__(self, img, phase='train'):\n","        \"\"\"\n","        Parameters\n","        ----------\n","        phase: 'train' or 'val'\n","        \"\"\"\n","        return self.data_transform[phase](img)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B9deKOkyKOQw","colab_type":"code","colab":{}},"source":["# # Check operation of pre-processing when training\n","\n","img_file_path = './data/goldenretriever-3724972_640.jpg'\n","img = Image.open(img_file_path)\n","\n","plt.imshow(img)\n","plt.show()\n","\n","size = 224\n","mean = (0.485, 0.456, 0.406)\n","std = (0.229, 0.224, 0.225)\n","\n","transform = ImageTransform(size, mean, std)\n","img_transformed = transform(img, phase='train')\n","\n","img_transformed = img_transformed.permute(1, 2, 0)\n","img_transformed = np.clip(img_transformed, 0, 1)\n","plt.imshow(img_transformed)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UGgajkyEMl11","colab_type":"text"},"source":["### Create file_path_list"]},{"cell_type":"code","metadata":{"id":"wEtDkmHtLq4-","colab_type":"code","colab":{}},"source":["def make_data_path_list(phase='train'):\n","\n","    root_path = './data/hymenoptera_data/'\n","    target_path = os.path.join(root_path + phase + '/**/*.jpg')\n","    print(target_path)\n","\n","    path_list = []\n","\n","    # Get file path to sub directory using glob\n","    for path in glob.glob(target_path):\n","        path_list.append(path)\n","    return path_list"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AerOcJhGNt-u","colab_type":"code","colab":{}},"source":["train_list = make_data_path_list('train')\n","val_list = make_data_path_list('val')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HbQw3aNUOhKh","colab_type":"code","colab":{}},"source":["train_list"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wufrR3REO0gF","colab_type":"text"},"source":["### Create Dataset of hymenoptera"]},{"cell_type":"code","metadata":{"id":"d6qZ_pBGOmfi","colab_type":"code","colab":{}},"source":["class HymenopteraDataset(data.Dataset):\n","    \"\"\" The Dataset of ant & bee(hymenoptera). Inherit Dataset class\n","\n","    Attribute:\n","        file_list:(list)\n","            the list of image_path\n","        transform:(object)\n","            the instance of pre-processing class\n","        phase: 'train' or 'test'\n","    \"\"\"\n","\n","    def __init__(self, file_list, transform=None, phase='train'):\n","        self.file_list = file_list\n","        self.transform = transform\n","        self.phase = phase\n","    \n","    def __len__(self):\n","        return len(self.file_list) # return the number of image\n","    \n","    def __getitem__(self, index):\n","        \"\"\" \n","        Get data typed Tensor and label after pre-processing\n","        \"\"\"\n","\n","        # load index_th image\n","        img_path = self.file_list[index]\n","        img = Image.open(img_path)\n","\n","        # pre-process image\n","        img_transformed = self.transform(img, self.phase)\n","\n","        # extract label of image from file_name\n","        if self.phase == 'train':\n","            label = img_path[30:34]\n","        elif self.phase == 'val':\n","            label = img_path[28:32]\n","        \n","        # transform label into number\n","        if label == 'ants':\n","            label = 0\n","        elif label == 'bees':\n","            label = 1\n","        \n","        return img_transformed, label"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JPs-a-Vlbzjy","colab_type":"code","colab":{}},"source":["train_dataset = HymenopteraDataset(\n","    file_list=train_list, transform=ImageTransform(size, mean, std), phase='train')\n","val_dataset = HymenopteraDataset(\n","    file_list=val_list, transform=ImageTransform(size, mean, std), phase='val')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KRBE8uS9cg3v","colab_type":"code","colab":{}},"source":["index = 0\n","print(train_dataset.__getitem__(index)[0].size())\n","print(train_dataset.__getitem__(index)[1])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0lUDjbePc7iE","colab_type":"text"},"source":["## Create DataLoader"]},{"cell_type":"code","metadata":{"id":"-Y1nK26yczWK","colab_type":"code","colab":{}},"source":["batch_size = 32\n","\n","# Create DataLoader\n","train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n","\n","dataloaders_dict = {'train': train_dataloader, 'val': val_dataloader}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uSIrrenZfHFj","colab_type":"code","colab":{}},"source":["# Check operation\n","batch_iter = iter(dataloaders_dict['train'])\n","inputs, labels = next(batch_iter)\n","\n","print(f'1st input_size: {inputs.size()}')\n","print(f'1st label: {labels}')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ImCYHJbygm-w","colab_type":"text"},"source":["## Create network model"]},{"cell_type":"code","metadata":{"id":"_vbbqlM7gS6H","colab_type":"code","colab":{}},"source":["# Load pre-trained VGG-16\n","# Generate insatance of VGG-16\n","use_pretrained = True\n","model = models.vgg16(pretrained=use_pretrained)\n","\n","# Change output_unit of last layer to out_features=2\n","model.classifier[6] = nn.Linear(in_features=4096, out_features=2)\n","\n","# Setting training mode\n","model.train()\n","print('Complete setting network! Loaded pre-trained parameter, set training mode.')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rEna_67iixu7","colab_type":"text"},"source":["## Setting loss function, optimizer"]},{"cell_type":"code","metadata":{"id":"V_j78vErisgz","colab_type":"code","colab":{}},"source":["# Define loss function\n","criterion = nn.CrossEntropyLoss()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lz8deGCbjI2B","colab_type":"code","colab":{}},"source":["#parameter to learn when transfer-learning\n","params_to_update = []\n","\n","#parameter_name\n","update_params_name = ['classifier.6.weight', 'classifier.6.bias']\n","\n","for name, param in model.named_parameters():\n","    if name in update_params_name:\n","        param.requires_grad = True\n","        params_to_update.append(param)\n","        print(name)\n","    else:\n","        param.requires_grad = False\n","\n","print('################')\n","print(params_to_update)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"icFFGL3ekeQE","colab_type":"code","colab":{}},"source":["# Set optimizer\n","optimizer = optim.SGD(params=params_to_update, lr=0.001, momentum=0.9)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LyqDuUkclP8S","colab_type":"text"},"source":["## Do training and validation"]},{"cell_type":"code","metadata":{"id":"Yqe2UZJslOZ9","colab_type":"code","colab":{}},"source":["def train_model(model, dataloaders_dict, criterion, optimizer, num_epochs):\n","\n","    # train_loss = []\n","    # train_acc = []\n","    # val_loss = []\n","    # val_acc = []\n","\n","    for epoch in range(num_epochs):\n","        print(f'epoch{epoch+1}/{num_epochs}')\n","        print('----------------------------')\n","\n","        for phase in ['train', 'val']:\n","            if phase == 'train':\n","                model.train()\n","            else:\n","                model.eval()\n","            \n","            epoch_loss = 0.0 # sum of epoch loss\n","            epoch_corrects = 0 # the number of epoch correction\n","\n","            if (epoch==0) and (phase=='train'):\n","                continue # to check validation performance when un-learning\n","            \n","            for inputs, labels in tqdm(dataloaders_dict[phase]):\n","\n","                # initialize optimizer\n","                optimizer.zero_grad()\n","\n","                # calculate forward\n","                with torch.set_grad_enabled(phase=='train'):\n","                    outputs = model(inputs)\n","                    loss = criterion(outputs, labels)\n","                    _, preds = torch.max(outputs,1)\n","\n","                    # when training, do backpropagation\n","                    if phase == 'train':\n","                        loss.backward()\n","                        optimizer.step()\n","\n","                    epoch_loss += loss.item() * inputs.size(0)\n","                    epoch_corrects += torch.sum(preds==labels.data)\n","                    \n","            epoch_loss /= len(dataloaders_dict[phase].dataset)\n","            epoch_acc = epoch_corrects.float()/len(dataloaders_dict[phase].dataset)\n","\n","            print(f'{phase} Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}')\n","    # plt.plot(train_loss, label='train loss')\n","    # plt.plot(val_loss, label='validation loss')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4Rfh7WvpqvCe","colab_type":"code","colab":{}},"source":["num_epochs = 3\n","train_model(model, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xCQpI_dyp7rx","colab_type":"text"},"source":["# Fine-tuning"]},{"cell_type":"code","metadata":{"id":"Ae81AFnf4O1h","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1599615368694,"user_tz":-540,"elapsed":663,"user":{"displayName":"Daisuke Kubo","photoUrl":"","userId":"01125598221336647455"}},"outputId":"bf92e482-a878-44a5-dce4-14a7844e039c"},"source":["train_list = make_data_path_list('train')\n","val_list = make_data_path_list('val')"],"execution_count":30,"outputs":[{"output_type":"stream","text":["./data/hymenoptera_data/train/**/*.jpg\n","./data/hymenoptera_data/val/**/*.jpg\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QeayoVhcmrCO","colab_type":"code","colab":{}},"source":["size = 224\n","mean = (0.485, 0.456, 0.406)\n","std = (0.229, 0.224, 0.225)\n","\n","# Create Dateset\n","train_dataset = HymenopteraDataset(train_list, transform=ImageTransform(size, mean, std), phase='train')\n","val_dataset = HymenopteraDataset(val_list, transform=ImageTransform(size, mean, std), phase='val')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ilX9O1RgnS3Z","colab_type":"code","colab":{}},"source":["# Create DataLoader\n","batch_size = 32\n","train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hAxDobh8n45C","colab_type":"code","colab":{}},"source":["dataloaders_dict = {'train': train_dataloader, 'val': val_dataloader}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"I-bBSYN6oGCH","colab_type":"code","colab":{}},"source":["use_pretrained = True\n","model = models.vgg16(pretrained=use_pretrained)\n","\n","model.classifier[6] = nn.Linear(in_features=4096, out_features=2)\n","model.train()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"80XU68b1odrX","colab_type":"code","colab":{}},"source":["criterion = nn.CrossEntropyLoss()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QR0kfzL5pRTF","colab_type":"code","colab":{}},"source":["# Storage each parameters to learn in fine-tuning\n","\n","params_to_update_1 = []\n","params_to_update_2 = []\n","params_to_update_3 = []\n","\n","update_params_name_1 = ['features']\n","update_params_name_2 = ['classifier.0.weight', 'classifier.0.bias', 'classifier.3.weight', 'classifier.3.bias']\n","update_params_name_3 = ['classifier.6.weight', 'classifier.6.bias']\n","\n","for name, param in model.named_parameters():\n","    if update_params_name_1[0] in name:\n","        param.requires_grad = True\n","        params_to_update_1.append(param)\n","\n","    elif name in update_params_name_2:\n","        param.requires_grad = True\n","        params_to_update_2.append(param)\n","\n","    elif name in update_params_name_3:\n","        param.requires_grad = True\n","        params_to_update_3.append(param)\n","    \n","    else:\n","        param.requires_grad = False"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cw0zCeQYeQHN","colab_type":"code","colab":{}},"source":["# Setting optimizer\n","optimizer = optim.SGD([\n","    {'params': params_to_update_1, 'lr': 1e-4},\n","    {'params': params_to_update_2, 'lr': 5e-4},\n","    {'params': params_to_update_3, 'lr': 1e-3}\n","], momentum=0.9)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qzL25UVxfEAc","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599616297463,"user_tz":-540,"elapsed":1720,"user":{"displayName":"Daisuke Kubo","photoUrl":"","userId":"01125598221336647455"}}},"source":["def train_model(model, dataloaders_dict, criterion, optimizer, num_epochs):\n","    \"\"\"\n","    training model\n","    \"\"\"\n","\n","    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","    print(f'using device: {device}')\n","\n","    model.to(device)\n","    \n","    # Accelerate GPU speed\n","    torch.backends.cudnn.benchmark = True\n","\n","    for epoch in range(num_epochs):\n","        print(f'Epoch:{epoch+1}/{num_epochs}')\n","        print('-----------------------------')\n","\n","        for phase in ['train', 'val']:\n","            if phase == 'train':\n","                model.train()\n","            elif phase == 'val':\n","                model.eval()\n","            \n","            epoch_loss = 0.0\n","            epoch_corrects = 0\n","\n","            if (epoch==0) and (phase=='train'):\n","                continue\n","            \n","            for inputs, labels in dataloaders_dict[phase]:\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","\n","                optimizer.zero_grad()\n","\n","                with torch.set_grad_enabled(phase=='train'):\n","                    outputs = model(inputs)\n","                    loss = criterion(outputs, labels)\n","                    _ , preds = torch.max(outputs, 1)\n","\n","                    if phase == 'train':\n","                        loss.backward()\n","                        optimizer.step()\n","                    \n","                    epoch_loss += loss.item() * inputs.size(0)\n","                    epoch_corrects += torch.sum(preds==labels.data)\n","            \n","            epoch_loss /= len(dataloaders_dict[phase].dataset)\n","            epoch_acc = epoch_corrects.float()/len(dataloaders_dict[phase].dataset)\n","\n","            print(f'{phase} Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}')"],"execution_count":36,"outputs":[]},{"cell_type":"code","metadata":{"id":"PslxibikjQCy","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":717},"executionInfo":{"status":"ok","timestamp":1599616381175,"user_tz":-540,"elapsed":64363,"user":{"displayName":"Daisuke Kubo","photoUrl":"","userId":"01125598221336647455"}},"outputId":"4ad0cc01-ef1e-4fed-da4e-7d929790afbc"},"source":["num_epochs = 10\n","train_model(model, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs)"],"execution_count":38,"outputs":[{"output_type":"stream","text":["using device: cuda\n","Epoch:1/10\n","-----------------------------\n","val Loss: 0.1654, Acc: 0.9608\n","Epoch:2/10\n","-----------------------------\n","train Loss: 0.1643, Acc: 0.9424\n","val Loss: 0.1201, Acc: 0.9542\n","Epoch:3/10\n","-----------------------------\n","train Loss: 0.0982, Acc: 0.9588\n","val Loss: 0.1100, Acc: 0.9608\n","Epoch:4/10\n","-----------------------------\n","train Loss: 0.0741, Acc: 0.9712\n","val Loss: 0.1019, Acc: 0.9608\n","Epoch:5/10\n","-----------------------------\n","train Loss: 0.0533, Acc: 0.9835\n","val Loss: 0.0989, Acc: 0.9608\n","Epoch:6/10\n","-----------------------------\n","train Loss: 0.0585, Acc: 0.9835\n","val Loss: 0.0982, Acc: 0.9608\n","Epoch:7/10\n","-----------------------------\n","train Loss: 0.0339, Acc: 0.9918\n","val Loss: 0.1019, Acc: 0.9542\n","Epoch:8/10\n","-----------------------------\n","train Loss: 0.0444, Acc: 0.9918\n","val Loss: 0.1106, Acc: 0.9542\n","Epoch:9/10\n","-----------------------------\n","train Loss: 0.0315, Acc: 0.9918\n","val Loss: 0.1138, Acc: 0.9542\n","Epoch:10/10\n","-----------------------------\n","train Loss: 0.0162, Acc: 1.0000\n","val Loss: 0.1156, Acc: 0.9477\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GuhrtP3fjpgZ","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599616573105,"user_tz":-540,"elapsed":3227,"user":{"displayName":"Daisuke Kubo","photoUrl":"","userId":"01125598221336647455"}}},"source":["save_path = './param_fine_tuning.pth'\n","torch.save(model.state_dict(), save_path)"],"execution_count":40,"outputs":[]},{"cell_type":"code","metadata":{"id":"16x1EEIBk7il","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}